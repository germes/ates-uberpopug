
**Миграция на новую логику - разделение title задачи на два поля**

1) Расширяем модели и таблицы во всех сервисах, где используются поля. На этом этапе валидацию не добавляем или не включаем, поля можно не выводить
2) Выделяем новую версию событий, которые передают title задачи, обновляем схему
3) Вносим изменения в логику консьюмеров, чтобы они умели читать события V2 и правильно сохранять их в БД. Раскатываем новую схему по сервисам
4) Тестируем работу консьюмеров с последней версией события. При этом первая версия должна так же нормально продолжать работать
5) Вносим изменения в логику продьюсеров для отправки событий V2. Выводим поле в jira_id в интерфейс и включаем валидацию - больше указать jira-id в title невозможно.
6) Проверяем корректность работы всей системы с событиями V2.
7) Планируем удаление логики в консьюмерах и продьюсерах, отвечающей за отправку/обработку событий V1. 

**Миграция на новую логику - смена названий статусов задач**

Предусловия - статусы в системе хранятся в каждом сервисе в виде таблицы-справочника, условно такого вида:
 - ID статуса
 - label
 - title

(как вариант это могут быть не таблицы, а константы в коде, существенно на реализацию и процесс смены это не повлияет)

Идентификаторы статусов внутри сервисов теоретически могут отличаться, так как мы явно не передаем статусы, а только события.

В таком случае для изменения названий статусов нужно внести изменения в таблицы-справочники на каждом сервисе, не меняя остальную логику.

**Schema registry**

Для реализации schema registry будем использовать собственную библиотеку на базе https://github.com/justinrainbow/json-schema

По сути делаем обертку aTES Schema Registry, в которой:
1) Храним в отдельной папке все схемы по событиям и версиям
2) Для непосредственной валидации используем justinrainbow/json-schema
3) Библиотеку подключаем как зависимость ко всем сервисам в системе и обновляем во всех сервисах при деплое

**Выбрать стратегию обработки ошибок в событиях связанных с системой аккаунтинга**

Предусловия - мы используем MySQL базу данных.

Будем использовать следующие схемы:
1) дополнение данных в таблице разными событиями, т.е. если получаем BE раньше, чем CUD - то создаем пустую строку с нужным public_id, данные в которой уже будут дополнены из CUD-события
   1) для реализации используем SELECT FOR UPDATE в связке с INSERT/UPDATE в MySQL, что приводит к локу записи с public_id и позволяет безболезненно обрабатывать параллельные запросы
2) retry - для событий, который отправить не удалось.
   1) в каждом сервисе заводим таблицу, куда складываем события, которые не удалось отправить по какой-то причине
   2) события группируем по топикам/продьюсерам
   3) минимизируем количество попыток отправить "откладывая" следующую попытку на N секунд после предыдущей
   4) при первой успешной отправке сбрасываем счетчики для все событий, ускоряя отправку
3) retry queue - для событий, которые обработать не удалось
   1) если событие не удалось обработать консьюмером - мы складываем его в отдельный топик / очередь для повторной обработки